# üß† Optimizaci√≥n de Memoria - RadarCol API

## üìä Problema: "Out of Memory (used over 512MB)"

Este documento explica c√≥mo resolver el error de memoria en ambientes con recursos limitados (como Render free tier con 512MB RAM).

---

## üîç Diagn√≥stico del Problema

El motor de an√°lisis RadarCol utiliza varios componentes que consumen memoria:

| Componente | Consumo RAM | ¬øOpcional? |
|------------|-------------|------------|
| FastAPI + Uvicorn | ~50-80MB | ‚ùå No |
| scikit-learn (IsolationForest) | ~30-50MB | ‚ùå No |
| NumPy + Pandas | ~40-60MB | ‚ùå No |
| Groq API Client | ~10-20MB | ‚ùå No |
| **SentenceTransformer (Embeddings)** | **~400-800MB** | ‚úÖ **S√≠** |
| SHAP Explainer | ~30-50MB | ‚úÖ S√≠ |
| **TOTAL (sin embeddings)** | **~200-300MB** | ‚úÖ Funciona en 512MB |
| **TOTAL (con embeddings)** | **~600-1000MB** | ‚ùå Excede 512MB |

### üí° Soluci√≥n: Sistema de Embeddings Opcional

Se implement√≥ un **Feature Toggle** que permite deshabilitar el modelo de embeddings pesado manteniendo la funcionalidad completa del sistema.

---

## ‚öôÔ∏è Configuraci√≥n

### Opci√≥n 1: Modo Ligero (Recomendado para Free Tier)

**Variables de entorno:**
```env
ENABLE_EMBEDDINGS=false
```

**Caracter√≠sticas:**
- ‚úÖ Consumo: ~200-300MB RAM
- ‚úÖ Funciona en Render free tier (512MB)
- ‚úÖ An√°lisis ML (IsolationForest) completo
- ‚úÖ An√°lisis LLM (Groq) completo
- ‚ö†Ô∏è Sin an√°lisis sem√°ntico de texto (score NLP = 0.0)
- ‚ö†Ô∏è Riesgo calculado 100% basado en variables financieras

**F√≥rmula de riesgo:**
```
Score Final = Score ML (100%)
```

### Opci√≥n 2: Modo Completo (Requiere >1GB RAM)

**Variables de entorno:**
```env
ENABLE_EMBEDDINGS=true
EMBEDDING_MODEL=paraphrase-multilingual-MiniLM-L12-v2
```

**Caracter√≠sticas:**
- ‚úÖ An√°lisis completo: ML + LLM + Sem√°ntica
- ‚úÖ Detecta anomal√≠as en texto del contrato
- ‚úÖ Score sem√°ntico por similitud con centroide
- ‚ùå Consumo: ~600-800MB RAM
- ‚ùå No funciona en Render free tier

**F√≥rmula de riesgo:**
```
Score Final = Score ML (70%) + Score NLP (30%)
```

---

## üéØ Patrones de Dise√±o Aplicados

### 1. **Feature Toggle Pattern**

Permite activar/desactivar funcionalidades mediante configuraci√≥n externa sin cambiar c√≥digo.

**Beneficios:**
- Deployment flexible
- A/B testing
- Rollback instant√°neo
- Adaptaci√≥n a recursos disponibles

**Implementaci√≥n:**
```python
# En settings.py
ENABLE_EMBEDDINGS = os.getenv("ENABLE_EMBEDDINGS", "false").lower() == "true"

# En analyzer.py
if self.enable_embeddings:
    self.model_nlp = SentenceTransformer(...)
else:
    self.model_nlp = None
    print("‚öôÔ∏è Embeddings deshabilitados (modo bajo consumo)")
```

### 2. **Strategy Pattern**

Dos estrategias para calcular el score de riesgo:

- **EmbeddingsStrategy**: usa an√°lisis sem√°ntico (score NLP)
- **NoEmbeddingsStrategy**: usa solo an√°lisis financiero (score ML)

**Implementaci√≥n:**
```python
# C√°lculo adaptativo de score combinado
if self.model_nlp:
    score_combinado = risk_ml * 0.7 + risk_nlp * 0.3
else:
    score_combinado = risk_ml  # 100% ML
```

### 3. **Graceful Degradation**

El sistema contin√∫a funcionando con capacidades reducidas en lugar de fallar completamente.

**Implementaci√≥n:**
```python
try:
    self.model_nlp = SentenceTransformer(...)
except Exception as e:
    print(f"‚ö†Ô∏è Error cargando embeddings: {e}")
    self.model_nlp = None
    self.enable_embeddings = False
```

---

## üìà Comparaci√≥n de Modos

| Aspecto | Modo Ligero | Modo Completo |
|---------|-------------|---------------|
| **RAM** | ~200-300MB | ~600-800MB |
| **Detecci√≥n anomal√≠as financieras** | ‚úÖ Completa | ‚úÖ Completa |
| **An√°lisis LLM (Groq)** | ‚úÖ Completo | ‚úÖ Completo |
| **An√°lisis sem√°ntico texto** | ‚ùå Deshabilitado | ‚úÖ Habilitado |
| **SHAP explicabilidad** | ‚úÖ S√≠ | ‚úÖ S√≠ |
| **Free tier compatible** | ‚úÖ S√≠ | ‚ùå No |
| **Precisi√≥n detecci√≥n** | Alta (ML + LLM) | Muy Alta (ML + LLM + NLP) |

---

## üöÄ Despliegue en Render Free Tier

### Configuraci√≥n Recomendada

```env
# Variables de entorno en Render Dashboard
GROQ_API_KEY=tu_api_key_aqui
ENABLE_EMBEDDINGS=false
CORS_ORIGINS=https://tu-frontend.com
BASE_URL=https://www.datos.gov.co/resource/jbjy-vk9h.json
RUTA_ARTEFACTOS=data/artifacts
```

### Verificaci√≥n de Memoria

Al iniciar el servicio, ver√°s logs como:

```
‚öôÔ∏è Inicializando Motor RadarCol (Groq + ML)...
   ‚ú® Cliente Groq conectado (llama-3.1-8b-instant)
   üìÅ Intentando cargar desde: data/artifacts
   ‚úÖ Artefactos cargados correctamente
   ‚úÖ SHAP explainer cargado correctamente
   ‚öôÔ∏è Embeddings deshabilitados (modo bajo consumo de memoria)
   ‚ÑπÔ∏è  El an√°lisis usar√° solo ML + LLM (sin score sem√°ntico)
üß† Embeddings habilitados: False
```

---

## üîß Troubleshooting

### Problema: Sigue dando error de memoria

**Soluciones adicionales:**

1. **Deshabilitar SHAP (opcional):**
   - Edita `analyzer.py` y comenta la carga de SHAP explainer
   - Ahorra ~30-50MB adicionales

2. **Optimizar requirements.txt:**
   ```txt
   # Usar versiones espec√≠ficas m√°s ligeras
   scikit-learn==1.3.0  # No usar 1.5.x que es m√°s pesada
   numpy>=1.21.0,<2.0.0  # NumPy 2.x consume m√°s memoria
   ```

3. **Lazy loading de modelos:**
   - Los modelos se cargan solo una vez al iniciar
   - No se recargan en cada request

### Problema: Quiero habilitar embeddings en free tier

**No es posible sin modificaciones mayores:**

- Render free tier = 512MB fijo
- Embeddings + App = ~600-800MB
- Alternativas:
  1. Upgrade a plan pago ($7/mes con 512MB-2GB)
  2. Usar otro proveedor (Railway, Fly.io con m√°s RAM gratuita)
  3. Implementar embeddings como servicio separado

---

## üìö Referencias de Aprendizaje

### Patrones Aplicados

1. **Feature Toggle:**
   - [Martin Fowler - Feature Toggles](https://martinfowler.com/articles/feature-toggles.html)
   - Permite cambios sin deployments

2. **Strategy Pattern:**
   - [Refactoring Guru - Strategy](https://refactoring.guru/design-patterns/strategy)
   - Intercambiar algoritmos en runtime

3. **Graceful Degradation:**
   - [MDN - Graceful Degradation](https://developer.mozilla.org/en-US/docs/Glossary/Graceful_degradation)
   - Fallback autom√°tico a funcionalidad reducida

### Optimizaci√≥n de Memoria en Python

- [Python Memory Management](https://realpython.com/python-memory-management/)
- [Optimizing ML Models](https://huggingface.co/docs/transformers/performance)

---

## ‚úÖ Resumen

1. **Problema:** Modelo de embeddings consume >400MB ‚Üí Excede l√≠mite de 512MB
2. **Soluci√≥n:** Feature Toggle para deshabilitar embeddings
3. **Resultado:** App funcional en 200-300MB (compatible con free tier)
4. **Trade-off:** Sin an√°lisis sem√°ntico, pero mantiene detecci√≥n de anomal√≠as financieras + LLM
5. **Arquitectura:** Limpia, extensible, permite reactivar embeddings en ambientes con m√°s recursos

**Para producci√≥n con recursos limitados: `ENABLE_EMBEDDINGS=false`** ‚úÖ
